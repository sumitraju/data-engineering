{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreational Beach Monitoring Program"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import re\n",
    "#import openpyxl\n",
    "#import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV files from a folder\n",
    "\n",
    "current_directory = str(os.getcwd()) + \"\\\\raw_data\\\\\"\n",
    "dataframes = []\n",
    "\n",
    "all_files = []\n",
    "\n",
    "for path, subdirs, files in os.walk(current_directory):\n",
    "    for name in files:\n",
    "        file_name = os.path.join(path, name)\n",
    "        format_matches = [\".csv\"]\n",
    "        exclue_matches = []\n",
    "        if name not in all_files:\n",
    "            if any([x in name for x in format_matches]):\n",
    "                if not any([y in file_name for y in exclue_matches]):\n",
    "                    try:\n",
    "                        current_dataframe = pd.read_csv(file_name, low_memory=False,sep=\",\")\n",
    "                        dataframes.append(current_dataframe)\n",
    "\n",
    "                        pass\n",
    "                    except Exception as e:\n",
    "                        print(\"Error reading file: \" + file_name)\n",
    "                        print(e)\n",
    "                else:\n",
    "                    print(\"Files Excluded : \" + file_name)\n",
    "            else:\n",
    "                print(\"Non Excel File: \" + file_name)\n",
    "        \n",
    "        all_files.append(name)\n",
    "all_files = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes[0].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if dataframes have the same columns\n",
    "\n",
    "if all([set(dataframes[0].columns) == set(df.columns) for df in dataframes]):\n",
    "    print('Datasets have the same columns')\n",
    "else:\n",
    "    print('Datasets do not have the same columns')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the columns names that have found in some columns but not in others. This way we can create those columns for all the dataframes\n",
    "\n",
    "columns = []\n",
    "    \n",
    "for x in range(0, len(dataframes), 1):\n",
    "    for y in range(0, len(dataframes), 1):\n",
    "        for z in range(0, len(dataframes[x].columns), 1):\n",
    "            #print(str(z) + \"||\"+ str(len(dataframes[y].columns))+ \"||\" + str(y))\n",
    "            if(dataframes[x].columns[z] in dataframes[y].columns):\n",
    "                pass\n",
    "            else:\n",
    "                if (dataframes[x].columns[z] in columns):\n",
    "                    pass\n",
    "                else:\n",
    "                    columns.append(dataframes[x].columns[z])\n",
    "                \n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all the dataframes into one\n",
    "\n",
    "recreational_beach_monitoring_raw = pd.concat(dataframes)\n",
    "recreational_beach_monitoring_raw.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Combined Dataset to a CSV\n",
    "\n",
    "recreational_beach_monitoring_raw.to_csv(\"data/recreational_beach_monitoring_raw.csv\", sep=',',index=False,encoding='utf-8-sig')\n",
    "\n",
    "#Shape of row data\n",
    "recreational_beach_monitoring_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a copy of the dataset\n",
    "\n",
    "recreational_beach_monitoring_p1 = recreational_beach_monitoring_raw.copy()\n",
    "recreational_beach_monitoring_p1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -9999 with NaN\n",
    "#nb_air_quality_p1 = nb_air_quality_p1.replace(-9999,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_datetime_format(dt_str):\n",
    "    formats_to_check = [\n",
    "        '%Y/%m/%d %I:%M:%S %p',\n",
    "        '%Y-%m-%d %I:%M:%S %p',\n",
    "        '%Y/%m/%d %H:%M:%S',\n",
    "        '%Y-%m-%d %H:%M:%S',\n",
    "        '%d/%m/%Y %I:%M:%S %p',\n",
    "        '%d-%m-%Y %I:%M:%S %p',\n",
    "        '%d/%m/%Y %H:%M:%S',\n",
    "        '%d-%m-%Y %H:%M:%S',\n",
    "        '%Y/%m/%d',\n",
    "        '%Y-%m-%d',\n",
    "        '%d/%m/%Y',\n",
    "        '%d-%m-%Y',\n",
    "    ]\n",
    "\n",
    "    for fmt in formats_to_check:\n",
    "        try:\n",
    "            datetime.datetime.strptime(dt_str, fmt)\n",
    "            return fmt\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "dt_str = \"2004/03/04\"\n",
    "format_found = find_datetime_format(dt_str)\n",
    "if format_found:\n",
    "    print(f\"Format found: {format_found}\")\n",
    "else:\n",
    "    print(\"Format not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_air_quality_p1[\"DATE_TIME\"] = nb_air_quality[\"DATE_TIME\"].replace('24:00','00:00' , regex=True)\n",
    "\n",
    "recreational_beach_monitoring_p1[\"FromDate\"] = pd.to_datetime(recreational_beach_monitoring_p1[\"FromDate\"],format='%Y/%m/%d')\n",
    "\n",
    "recreational_beach_monitoring_p1[\"YEAR\"] = recreational_beach_monitoring_p1[\"FromDate\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p1.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Station information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename two columns before station informtion\n",
    "recreational_beach_monitoring_p1.rename(columns={'Station': 'STATION_NAME', 'FromDate': 'DATE'}, inplace=True)\n",
    "\n",
    "#Import data \n",
    "\n",
    "station_information = pd.read_csv(\"data/recreational-beach-monitoring-stations-sites.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DMS (degrees, minutes, seconds) to DD (decimal degrees)\n",
    "def dms2dd(degrees, minutes, seconds, direction):\n",
    "    dd = float(degrees) + float(minutes)/60 + float(seconds)/(60*60)\n",
    "    if direction == 'S' or direction == 'W':\n",
    "        dd *= -1\n",
    "    return dd\n",
    "\n",
    "def dd2dms(dms,dd, pre_fix_latlong):\n",
    "    if(pd.isnull(dms) == True and pd.isnull(dd) == False):\n",
    "        d = int(dd)\n",
    "        md = abs(dd - d) * 60\n",
    "        m = int(md)\n",
    "        sd = (md - m) * 60\n",
    "        #return [d, m, sd] \n",
    "        #print(\"%s %s˚ %s' %s\\\"\" % (pre_fix_latlong,abs(d),m,round(sd,1)))\n",
    "        return \"%s %s˚ %s' %s\\\"\" % (pre_fix_latlong,abs(d),m,round(sd,1))\n",
    "    return dms\n",
    "\n",
    "def parse_dms(dms,latlong):\n",
    "    if(pd.isnull(dms) != True):\n",
    "        #print(dms)\n",
    "        dms=dms.replace('\"','')\n",
    "        degDirection, minutes, seconds = re.split('[˚\\']', dms)\n",
    "        direction,deg = re.split('[\\s]', degDirection)\n",
    "        #print(deg, minutes, seconds, direction)\n",
    "        latLng = dms2dd(deg, minutes, seconds, direction)\n",
    "\n",
    "        return (latLng)\n",
    "    else:\n",
    "        return latlong\n",
    "\n",
    "#dd = parse_dms(\"36°57'9' N 110°4'21' W\")\n",
    "\n",
    "#print(parse_dms(\"W 67˚ 44' 01.3\",np.nan))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_information[\"LATITUDE\"] = station_information.apply(lambda x: parse_dms(x[\"DMS_LATITUDE\"],x[\"LATITUDE\"]),axis=1)\n",
    "station_information[\"LONGITUDE\"] = station_information.apply(lambda x: parse_dms(x[\"DMS_LONGITUDE\"],x[\"LONGITUDE\"]),axis=1)\n",
    "\n",
    "station_information[\"DMS_LATITUDE\"] = station_information.apply(lambda x: dd2dms(x[\"DMS_LATITUDE\"],x[\"LATITUDE\"],\"N\"),axis=1)\n",
    "station_information[\"DMS_LONGITUDE\"] = station_information.apply(lambda x: dd2dms(x[\"DMS_LONGITUDE\"],x[\"LONGITUDE\"],\"W\"),axis=1)\n",
    "\n",
    "#Export stations to a CSV\n",
    "\n",
    "station_information.to_csv(\"data/recreational-beach-monitoring-stations-sites.csv\", sep=',',index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attach station information\n",
    "\n",
    "recreational_beach_monitoring_p1 = pd.merge(recreational_beach_monitoring_p1, station_information[[\"STATION_ID\",\"STATION_NAME\",\"LATITUDE\",\"LONGITUDE\"]],  how='left', left_on=['STATION_NAME'], right_on = ['STATION_NAME'])\n",
    "\n",
    "recreational_beach_monitoring_p1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -9999 with NaN\n",
    "#nb_surface_water_monitoring_p1 = nb_surface_water_monitoring_p1.replace(-9999,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null values\n",
    "pd.set_option('display.max_rows',None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "recreational_beach_monitoring_p1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')\n",
    "#pd.reset_option('display.max_columns')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create another copy of the dataset for futher pre-processing\n",
    "\n",
    "Some methods are slow when processing data. Creating a copy of a dataset will allow us not to run the entire code during data development. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p2 = recreational_beach_monitoring_p1.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check and remove null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_columns_dataset(dataset):\n",
    "    indexes = []\n",
    "    for i in range(0,len(dataset.columns),1):\n",
    "        if(len(dataset[dataset.columns[i]])==dataset[dataset.columns[i]].isna().sum()):\n",
    "            indexes.append(dataset.columns[i])\n",
    "            print(dataset.columns[i])\n",
    "   \n",
    "    dataset.drop(indexes,inplace=True, axis=1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p2 = drop_empty_columns_dataset(recreational_beach_monitoring_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p2.columns.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove unit information field value where there is no analyte value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unit_from_empty(unitVal, unitName):\n",
    "    if(unitVal == \"\" or math.isnan(unitVal)):\n",
    "        return np.nan\n",
    "    return unitName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" nb_surface_water_monitoring_p2[\"SO2_INFO\"] = nb_surface_water_monitoring_p2.apply(lambda x: remove_unit_from_empty(x[\"SO2\"],x[\"SO2_INFO\"]),axis=1) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recreational_beach_monitoring_p2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(column_name):\n",
    "    unit_only = re.findall('\\((.*?)\\)',column_name)\n",
    "    unit_only = unit_only[0] if len(unit_only) > 0 else unit_only\n",
    "    column_name_cleaned = re.sub('\\((.*?)\\)','',column_name)\n",
    "    column_name_cleaned = column_name_cleaned.replace(\" - \", \"-\")\n",
    "    column_name_cleaned = column_name_cleaned.replace(\"  \", \"_\")\n",
    "    column_name_cleaned = column_name_cleaned.replace(\" \", \"_\")\n",
    "    column_name_cleaned = column_name_cleaned.replace(\"-\", \"_\")\n",
    "    column_name_cleaned = column_name_cleaned.replace(\".\", \"_\")\n",
    "    column_name_cleaned = column_name_cleaned.replace(\",\", \"_\")\n",
    "    column_name_cleaned = column_name_cleaned.upper()\n",
    "    return [column_name_cleaned, unit_only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get units from columns and store in a dataframe\n",
    "\n",
    "recreational_beach_monitoring_units = pd.DataFrame(columns = ['UNIT_NAME_ORIGINAL','UNIT_NAME_CLEANED', 'UNIT'])\n",
    "\n",
    "non_unit_columns = ['STATION_NAME', 'DATE', 'Subprg', 'Field Number', 'Medium Code', 'Medium Desc', 'YEAR', 'LATITUDE', 'LONGITUDE','Flag','STATION_ID']\n",
    "# append rows to an empty DataFrame\n",
    "for i in range(0,len(recreational_beach_monitoring_p2.columns),1):\n",
    "    if not any([y in recreational_beach_monitoring_p2.columns[i] for y in non_unit_columns]):\n",
    "        #print(clean_column_names(recreational_beach_monitoring_p2.columns[i]))\n",
    "        recreational_beach_monitoring_units_row = pd.DataFrame({'UNIT_NAME_ORIGINAL':recreational_beach_monitoring_p2.columns[i],'UNIT_NAME_CLEANED':clean_column_names(recreational_beach_monitoring_p2.columns[i])[0], 'UNIT':clean_column_names(recreational_beach_monitoring_p2.columns[i])[1]}, index=[i])\n",
    "        recreational_beach_monitoring_units = pd.concat([recreational_beach_monitoring_units, recreational_beach_monitoring_units_row])\n",
    "\n",
    "recreational_beach_monitoring_units[\"UNIT_NAME_CLEANED\"] = recreational_beach_monitoring_units[\"UNIT_NAME_CLEANED\"].replace(\"Þ_=TDS_RPC_LAB\",\"TDS_RPC_LAB_CALC\")\n",
    "\n",
    "#Export Combined Dataset to a CSV\n",
    "\n",
    "recreational_beach_monitoring_units.to_csv(\"data/recreational-beach-monitoring-units.csv\", sep=',',index=False,encoding='utf-8-sig')\n",
    "\n",
    "recreational_beach_monitoring_units.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename all columns\n",
    "\n",
    "recreational_beach_monitoring_p2 = recreational_beach_monitoring_p2.rename(columns=lambda x: clean_column_names(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually rename calculated variables\n",
    "\n",
    "recreational_beach_monitoring_p2 = recreational_beach_monitoring_p2.rename(columns={\"Þ_=TDS_RPC_LAB\":\"TDS_RPC_LAB_CALC\"})\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually drop columns \n",
    "\n",
    "recreational_beach_monitoring_p2 = recreational_beach_monitoring_p2.drop(['SUBPRG','MEDIUM_CODE','MEDIUM_DESC'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Round the Coulmns to 1 decimal point\n",
    "\n",
    "#cols = ['AL_ENV_LAB', 'ALK_G_ENV_LAB']\n",
    "\n",
    "#recreational_beach_monitoring_p2[cols] = recreational_beach_monitoring_p2[cols].round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge multiple source data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p3 = recreational_beach_monitoring_p2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a row of wrong data as suggested by the Water Sciences team \n",
    "\n",
    "recreational_beach_monitoring_p3 = recreational_beach_monitoring_p3.drop(recreational_beach_monitoring_p3[(recreational_beach_monitoring_p3[\"STATION_NAME\"] == \"Mount Carleton Provincial Park - Station 1\") & (recreational_beach_monitoring_p3[\"DATE\"] == \"2020/07/15\") & (recreational_beach_monitoring_p3[\"FIELD_NUMBER\"] ==\"1448-20-29041\")].index)\n",
    "\n",
    "recreational_beach_monitoring_p3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p3 = drop_empty_columns_dataset(recreational_beach_monitoring_p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p3.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(recreational_beach_monitoring_p3[\"ALK_T_RPC_LAB_FLAG\"]) - recreational_beach_monitoring_p3[\"ALK_T_RPC_LAB_FLAG\"].isna().sum())\n",
    "#print(len(recreational_beach_monitoring_p3[\"ALK_T_ENV_LAB_FLAG\"]) - recreational_beach_monitoring_p3[\"ALK_T_ENV_LAB_FLAG\"].isna().sum())\n",
    "#print(len(recreational_beach_monitoring_p3[\"ALK_T_ENV_LAB_FLAG\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_groups(arr_values_analytes,dateval,station_id,source_of_val,empty_val):\n",
    "    \n",
    "    checknull = 0\n",
    "    analyte_val = np.nan\n",
    "    source_name = \"\"\n",
    "    for i in range(len(arr_values_analytes)):\n",
    "        if(str(arr_values_analytes[i]).strip() == \"\" or pd.isnull(arr_values_analytes[i])==True):\n",
    "            checknull += 1\n",
    "        else:\n",
    "            analyte_val =  arr_values_analytes[i]\n",
    "            source_name = source_of_val[i]\n",
    "    \n",
    "    if(len(arr_values_analytes)-checknull == 0):\n",
    "        #print(\"null group\" + str(dateval))\n",
    "        pass\n",
    "    elif(len(arr_values_analytes)-checknull == 1):\n",
    "        return str(analyte_val) + \"(\"+source_name +\")\"\n",
    "    else:\n",
    "        print(\"issue in group\" + str(dateval) +\"||\" + str(station_id))\n",
    "    \n",
    "    return empty_val\n",
    "\n",
    "#check_null_groups_vec = np.vectorize(check_null_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p3[\"AIR_TEMP_FIELD\"] = recreational_beach_monitoring_p3.apply(lambda x: check_null_groups([x[\"AIR_TEMP_FIELD_ENV\"],x[\"AIR_TEMP_FIELD_ENV_1\"]],x[\"DATE\"],x[\"STATION_ID\"],[\"ENV Field\",\"ENV Field.1\"],np.nan),axis=1)\n",
    "recreational_beach_monitoring_p3[\"E_COLI_MPN\"] = recreational_beach_monitoring_p3.apply(lambda x: check_null_groups([x[\"E_COLI_MPN_RPC_LAB\"],x[\"E_COLI_MPN_RPC_LAB_1\"]],x[\"DATE\"],x[\"STATION_ID\"],[\"RPC Lab\",\"RPC Lab.1\"],np.nan),axis=1)\n",
    "recreational_beach_monitoring_p3[\"E_COLI_MPN_FLAG\"] = recreational_beach_monitoring_p3.apply(lambda x: check_null_groups([x[\"E_COLI_MPN_RPC_LAB_FLAG\"],x[\"E_COLI_MPN_RPC_LAB_FLAG_1\"]],x[\"DATE\"],x[\"STATION_ID\"],[\"RPC Lab\",\"RPC Lab.1\"],np.nan),axis=1)\n",
    "recreational_beach_monitoring_p3[\"EC_MF\"] = recreational_beach_monitoring_p3.apply(lambda x: check_null_groups([x[\"EC_MF_RPC_LAB\"],x[\"EC_MF_RPC_LAB_2\"]],x[\"DATE\"],x[\"STATION_ID\"],[\"RPC Lab\",\"RPC Lab.2\"],np.nan),axis=1)\n",
    "recreational_beach_monitoring_p3[\"EC_MF_FLAG\"] = recreational_beach_monitoring_p3.apply(lambda x: check_null_groups([x[\"EC_MF_RPC_LAB_FLAG\"],x[\"EC_MF_RPC_LAB_FLAG_1\"],x[\"EC_MF_RPC_LAB_FLAG_2\"]],x[\"DATE\"],x[\"STATION_ID\"],[\"RPC Lab\",\"RPC Lab.1\",\"RPC Lab.2\"],np.nan),axis=1)\n",
    "recreational_beach_monitoring_p3[\"ENT_MPN\"] = recreational_beach_monitoring_p3.apply(lambda x: check_null_groups([x[\"ENT/MPN_RPC_LAB\"],x[\"ENT/MPN_RPC_LAB_1\"]],x[\"DATE\"],x[\"STATION_ID\"],[\"RPC Lab\",\"RPC Lab.1\"],np.nan),axis=1)\n",
    "recreational_beach_monitoring_p3[\"PH_FIELD\"] = recreational_beach_monitoring_p3.apply(lambda x: check_null_groups([x[\"PH_CLIENT_FLD\"],x[\"PH_FIELD_ENV\"],x[\"PH_FIELD_ENV_1\"]],x[\"DATE\"],x[\"STATION_ID\"],[\"Client Field\",\"ENV Field\",\"ENV Field.1\"],np.nan),axis=1)\n",
    "recreational_beach_monitoring_p3[\"TEMP_FIELD\"] = recreational_beach_monitoring_p3.apply(lambda x: check_null_groups([x[\"TEMP_FIELD_ENV\"],x[\"TEMP_FIELD_ENV_1\"],x[\"TEMP_UNKNOWN\"]],x[\"DATE\"],x[\"STATION_ID\"],[\"ENV Field\",\"ENV Field.1\",\"Unknown\"],np.nan),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate source columns\n",
    "\n",
    "def separate_source_columns(raw_value):\n",
    "    #print(raw_value)\n",
    "    if(pd.isnull(raw_value)==False):\n",
    "        #print(raw_value)\n",
    "        source_only = re.findall('\\((.*?)\\)',raw_value)\n",
    "        source_only = source_only[0] if len(source_only) > 0 else source_only\n",
    "        #print(source_only)\n",
    "        return source_only\n",
    "    else:\n",
    "        return \"\" \n",
    "        \n",
    "separate_source_columns_vec = np.vectorize(separate_source_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p3[\"AIR_TEMP_SOURCE\"] = separate_source_columns_vec(recreational_beach_monitoring_p3[\"AIR_TEMP_FIELD\"])\n",
    "recreational_beach_monitoring_p3[\"E_COLI_MPN_SOURCE\"] = separate_source_columns_vec(recreational_beach_monitoring_p3[\"E_COLI_MPN\"])\n",
    "recreational_beach_monitoring_p3[\"EC_MF_SOURCE\"] = separate_source_columns_vec(recreational_beach_monitoring_p3[\"EC_MF\"])\n",
    "recreational_beach_monitoring_p3[\"ENT_MPN_SOURCE\"] = separate_source_columns_vec(recreational_beach_monitoring_p3[\"ENT_MPN\"])\n",
    "recreational_beach_monitoring_p3[\"PH_FIELD_SOURCE\"] = separate_source_columns_vec(recreational_beach_monitoring_p3[\"PH_FIELD\"])\n",
    "recreational_beach_monitoring_p3[\"TEMP_FIELD_SOURCE\"] = separate_source_columns_vec(recreational_beach_monitoring_p3[\"TEMP_FIELD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove source data from analytes\n",
    "\n",
    "def remove_source_name(raw_value):\n",
    "    if(pd.isnull(raw_value)==False):\n",
    "        #print(raw_value)\n",
    "        value_cleaned = re.sub('\\((.*?)\\)','',raw_value)\n",
    "        #print(value_cleaned)\n",
    "        return value_cleaned\n",
    "    else:\n",
    "        return \"\"  \n",
    "        \n",
    "remove_source_name_vec = np.vectorize(remove_source_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p3[\"AIR_TEMP_FIELD\"] = remove_source_name_vec(recreational_beach_monitoring_p3[\"AIR_TEMP_FIELD\"])\n",
    "recreational_beach_monitoring_p3[\"E_COLI_MPN\"] = remove_source_name_vec(recreational_beach_monitoring_p3[\"E_COLI_MPN\"])\n",
    "recreational_beach_monitoring_p3[\"E_COLI_MPN_FLAG\"] = remove_source_name_vec(recreational_beach_monitoring_p3[\"E_COLI_MPN_FLAG\"])\n",
    "recreational_beach_monitoring_p3[\"EC_MF\"] = remove_source_name_vec(recreational_beach_monitoring_p3[\"EC_MF\"])\n",
    "recreational_beach_monitoring_p3[\"EC_MF_FLAG\"] = remove_source_name_vec(recreational_beach_monitoring_p3[\"EC_MF_FLAG\"])\n",
    "recreational_beach_monitoring_p3[\"ENT_MPN\"] = remove_source_name_vec(recreational_beach_monitoring_p3[\"ENT_MPN\"])\n",
    "recreational_beach_monitoring_p3[\"PH_FIELD\"] = remove_source_name_vec(recreational_beach_monitoring_p3[\"PH_FIELD\"])\n",
    "recreational_beach_monitoring_p3[\"TEMP_FIELD\"] = remove_source_name_vec(recreational_beach_monitoring_p3[\"TEMP_FIELD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p3.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename some flag columns\n",
    "\n",
    "recreational_beach_monitoring_p3 = recreational_beach_monitoring_p3.rename(columns={\"ENT/MPN_RPC_LAB_FLAG\":\"ENT_MPN_FLAG\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Missing Flag Columns\n",
    "\n",
    "recreational_beach_monitoring_p3['AIR_TEMP_FIELD_FLAG'] = \"\"\n",
    "recreational_beach_monitoring_p3['COND_FIELD_ENV_FLAG'] = \"\"\n",
    "recreational_beach_monitoring_p3['DO_FIELD_ENV_FLAG'] = \"\"\n",
    "recreational_beach_monitoring_p3['DOHBCHADV_RPC_LAB_FLAG'] = \"\"\n",
    "recreational_beach_monitoring_p3['DOHBCHRAIN_RPC_LAB_FLAG'] = \"\"\n",
    "recreational_beach_monitoring_p3['PH_FIELD_FLAG'] = \"\"\n",
    "recreational_beach_monitoring_p3['TEMP_FIELD_FLAG'] = \"\"\n",
    "recreational_beach_monitoring_p3['TURB_FIELD_ENV_FLAG'] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p3.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['E_COLI_MPN_RPC_LAB_FLAG', 'E_COLI_MPN_RPC_LAB_FLAG_1', 'EC_MF_RPC_LAB_FLAG', 'EC_MF_RPC_LAB_FLAG_1', 'EC_MF_RPC_LAB_FLAG_2', 'ENT_MPN_FLAG',  'E_COLI_MPN_FLAG', 'EC_MF_FLAG', 'AIR_TEMP_FIELD_FLAG', 'COND_FIELD_ENV_FLAG', 'DO_FIELD_ENV_FLAG', 'DOHBCHADV_RPC_LAB_FLAG', 'DOHBCHRAIN_RPC_LAB_FLAG',      'TEMP_FIELD_FLAG']\n",
    "\n",
    "recreational_beach_monitoring_p3[cols] = recreational_beach_monitoring_p3[cols].replace(np.nan,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty String to NaN\n",
    "\n",
    "cols = ['AIR_TEMP_FIELD', 'AIR_TEMP_FIELD_ENV', 'AIR_TEMP_FIELD_ENV_1',  'COND_FIELD_ENV', 'DO_FIELD_ENV', 'DOHBCHADV_RPC_LAB', 'DOHBCHRAIN_RPC_LAB', 'E_COLI_MPN', 'E_COLI_MPN_RPC_LAB', 'E_COLI_MPN_RPC_LAB_1', 'EC_MF', 'EC_MF_RPC_LAB', 'EC_MF_RPC_LAB_2', 'ENT/MPN_RPC_LAB', 'ENT/MPN_RPC_LAB_1', 'ENT_MPN',  'PH_CLIENT_FLD', 'PH_FIELD', 'PH_FIELD_ENV', 'PH_FIELD_ENV_1', 'TEMP_FIELD', 'TEMP_FIELD_ENV', 'TEMP_FIELD_ENV_1', 'TEMP_UNKNOWN', 'TURB_FIELD_ENV']\n",
    "\n",
    "recreational_beach_monitoring_p3[cols] = recreational_beach_monitoring_p3[cols].replace(\"\",np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recreational_beach_monitoring_p3['E_COLI_MPN_FLAG'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_missing_flag_col(non_numeric_value,flag_val):\n",
    "    if(pd.isnull(non_numeric_value)==False and (bool(re.search(\"^-?[0-9]\\d*(\\.\\d+)?$\", str(non_numeric_value)))==False and non_numeric_value !=np.nan)):\n",
    "        return non_numeric_value\n",
    "            \n",
    "    return flag_val\n",
    "\n",
    "create_missing_flag_col_vec = np.vectorize(create_missing_flag_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p3['AIR_TEMP_FIELD_FLAG'] = create_missing_flag_col_vec(recreational_beach_monitoring_p3['AIR_TEMP_FIELD'],recreational_beach_monitoring_p3['AIR_TEMP_FIELD_FLAG'])\n",
    "recreational_beach_monitoring_p3['COND_FIELD_ENV_FLAG'] = create_missing_flag_col_vec(recreational_beach_monitoring_p3['COND_FIELD_ENV'],recreational_beach_monitoring_p3['COND_FIELD_ENV_FLAG'])\n",
    "recreational_beach_monitoring_p3['DO_FIELD_ENV_FLAG'] = create_missing_flag_col_vec(recreational_beach_monitoring_p3['DO_FIELD_ENV'],recreational_beach_monitoring_p3['DO_FIELD_ENV_FLAG'])\n",
    "recreational_beach_monitoring_p3['DOHBCHADV_RPC_LAB_FLAG'] = create_missing_flag_col_vec(recreational_beach_monitoring_p3['DOHBCHADV_RPC_LAB'],recreational_beach_monitoring_p3['DOHBCHADV_RPC_LAB_FLAG'])\n",
    "recreational_beach_monitoring_p3['DOHBCHRAIN_RPC_LAB_FLAG'] = create_missing_flag_col_vec(recreational_beach_monitoring_p3['DOHBCHRAIN_RPC_LAB'],recreational_beach_monitoring_p3['DOHBCHRAIN_RPC_LAB_FLAG'])\n",
    "recreational_beach_monitoring_p3['E_COLI_MPN_FLAG'] = create_missing_flag_col_vec(recreational_beach_monitoring_p3['E_COLI_MPN'],recreational_beach_monitoring_p3['E_COLI_MPN_FLAG'])\n",
    "recreational_beach_monitoring_p3['EC_MF_FLAG'] = create_missing_flag_col_vec(recreational_beach_monitoring_p3['EC_MF'],recreational_beach_monitoring_p3['EC_MF_FLAG'])\n",
    "recreational_beach_monitoring_p3['ENT_MPN_FLAG'] = create_missing_flag_col_vec(recreational_beach_monitoring_p3['ENT_MPN'],recreational_beach_monitoring_p3['ENT_MPN_FLAG'])\n",
    "recreational_beach_monitoring_p3['PH_FIELD_FLAG'] = create_missing_flag_col_vec(recreational_beach_monitoring_p3['PH_FIELD'],recreational_beach_monitoring_p3['PH_FIELD_FLAG'])\n",
    "recreational_beach_monitoring_p3['TEMP_FIELD_FLAG'] = create_missing_flag_col_vec(recreational_beach_monitoring_p3['TEMP_FIELD'],recreational_beach_monitoring_p3['TEMP_FIELD_FLAG'])\n",
    "recreational_beach_monitoring_p3['TURB_FIELD_ENV_FLAG'] = create_missing_flag_col_vec(recreational_beach_monitoring_p3['TURB_FIELD_ENV'],recreational_beach_monitoring_p3['TURB_FIELD_ENV_FLAG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p4 = recreational_beach_monitoring_p3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove RPV from analyte columns\n",
    "\n",
    "recreational_beach_monitoring_p4[cols] = recreational_beach_monitoring_p4[cols].replace(\"RPV\",np.nan)\n",
    "recreational_beach_monitoring_p4[cols] = recreational_beach_monitoring_p4[cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove NT from flag columns as per the Water Sciences Team's suggestion\n",
    "\n",
    "cols = ['E_COLI_MPN_FLAG', 'ENT_MPN_FLAG', 'EC_MF_FLAG', 'TURB_FIELD_ENV_FLAG', 'TEMP_FIELD_FLAG', 'AIR_TEMP_FIELD_FLAG']\n",
    "\n",
    "recreational_beach_monitoring_p4[cols] = recreational_beach_monitoring_p4[cols].replace(\"NT\",np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert empty srting to nan values for flags \n",
    "\n",
    "cols = [ 'E_COLI_MPN_RPC_LAB_FLAG', 'E_COLI_MPN_RPC_LAB_FLAG_1', 'EC_MF_RPC_LAB_FLAG', 'EC_MF_RPC_LAB_FLAG_1', 'EC_MF_RPC_LAB_FLAG_2', 'ENT_MPN_FLAG',   'E_COLI_MPN_FLAG', 'EC_MF_FLAG', 'AIR_TEMP_FIELD_FLAG',  'COND_FIELD_ENV_FLAG',  'DO_FIELD_ENV_FLAG', 'DOHBCHADV_RPC_LAB_FLAG', 'DOHBCHRAIN_RPC_LAB_FLAG',   'PH_FIELD_FLAG', 'TEMP_FIELD_FLAG', 'TURB_FIELD_ENV_FLAG']\n",
    "\n",
    "recreational_beach_monitoring_p4[cols] = recreational_beach_monitoring_p4[cols].replace(\"\",np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"AIR_TEMP_SOURCE\", \"E_COLI_MPN_SOURCE\", \"EC_MF_SOURCE\", \"ENT_MPN_SOURCE\", \"PH_FIELD_SOURCE\", \"TEMP_FIELD_SOURCE\"]\n",
    "\n",
    "recreational_beach_monitoring_p4[cols] = recreational_beach_monitoring_p4[cols].replace(\".1\",\"\", regex=True)\n",
    "recreational_beach_monitoring_p4[cols] = recreational_beach_monitoring_p4[cols].replace(\".2\",\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop null columns\n",
    "recreational_beach_monitoring_p4 = drop_empty_columns_dataset(recreational_beach_monitoring_p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicate columns \n",
    "cols = ['AIR_TEMP_FIELD_ENV', 'AIR_TEMP_FIELD_ENV_1', 'E_COLI_MPN_RPC_LAB', 'E_COLI_MPN_RPC_LAB_1', 'E_COLI_MPN_RPC_LAB_FLAG', 'E_COLI_MPN_RPC_LAB_FLAG_1', 'EC_MF_RPC_LAB', 'EC_MF_RPC_LAB_2', 'EC_MF_RPC_LAB_FLAG', 'EC_MF_RPC_LAB_FLAG_1', 'EC_MF_RPC_LAB_FLAG_2', 'ENT/MPN_RPC_LAB', 'ENT/MPN_RPC_LAB_1', 'PH_FIELD_ENV', 'PH_FIELD_ENV_1', 'TEMP_UNKNOWN', 'TEMP_FIELD_ENV', 'TEMP_FIELD_ENV_1']\n",
    "\n",
    "#recreational_beach_monitoring_p4 = recreational_beach_monitoring_p4.drop(cols, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns suggested by the Water Sciences team\n",
    "\n",
    "cols = ['DOHBCHADV_RPC_LAB','TEMP_FIELD_SOURCE','PH_FIELD_SOURCE','TEMP_FIELD_ENV','PH_FIELD_ENV','FIELD_NUMBER']\n",
    "\n",
    "recreational_beach_monitoring_p4 = recreational_beach_monitoring_p4.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns suggested by the Water Sciences team\n",
    "\n",
    "recreational_beach_monitoring_p4 = recreational_beach_monitoring_p4.rename(columns={\"TEMP_FIELD\":\"TEMP_FIELD_ENV\", \"TEMP_FIELD_FLAG\":\"TEMP_FIELD_ENV_FLAG\", \"PH_FIELD\":\"PH_FIELD_ENV\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rearrange columns\n",
    "\n",
    "cols = ['STATION_NAME', 'STATION_ID', 'DATE', 'YEAR', 'LATITUDE', 'LONGITUDE', 'E_COLI_MPN', 'E_COLI_MPN_FLAG', 'ENT_MPN', 'ENT_MPN_FLAG', 'EC_MF', 'EC_MF_FLAG', 'TURB_FIELD_ENV', 'TEMP_FIELD_ENV', 'AIR_TEMP_FIELD', 'COND_FIELD_ENV', 'DO_FIELD_ENV', 'DOHBCHRAIN_RPC_LAB', 'PH_FIELD_ENV']\n",
    "\n",
    "recreational_beach_monitoring_p4 = recreational_beach_monitoring_p4[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_p4.columns.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a final copy of processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring = recreational_beach_monitoring_p4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Combined Dataset to a CSV\n",
    "\n",
    "recreational_beach_monitoring.to_csv(\"data/recreational_beach_monitoring.csv\", sep=',',index=False,encoding='utf-8-sig')\n",
    "\n",
    "#Shape of row data\n",
    "recreational_beach_monitoring.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring.columns.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Plot null values\n",
    "def plot_null_values(dataset,group_by,year_filter_switch, year_filter):\n",
    "    if year_filter_switch:\n",
    "        dataset = dataset[(dataset['YEAR'] == year_filter)]\n",
    "    \n",
    "    dataset = dataset.groupby([group_by])\n",
    "    # extract keys from groups\n",
    "    keys = dataset.groups.keys()\n",
    "\n",
    "    totalCols=1\n",
    "    totalRows=math.ceil(len(dataset)/totalCols)\n",
    "    \n",
    "    fig = plt.figure(figsize=((totalCols+3)*4,(totalRows+1)*5))\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.7)\n",
    "\n",
    "    for index, x in enumerate(keys):\n",
    "        null_columns = []\n",
    "        null_column_values = []\n",
    "\n",
    "        #print(dataset.get_group(x).columns[2])\n",
    "\n",
    "        for i in range(0,len(dataset.get_group(x).columns),1):\n",
    "            if(dataset[dataset.get_group(x).columns[i]].get_group(x).isna().sum() > 0):\n",
    "                null_columns.append(dataset.get_group(x).columns[i])\n",
    "                null_column_values.append(dataset[dataset.get_group(x).columns[i]].get_group(x).isna().sum())\n",
    "\n",
    "        globals()[f\"ax_count_plots_{index}\"] = fig.add_subplot(totalRows,totalCols,(index+1))\n",
    "        globals()[f\"ax_count_plots_{index}\"].set_title(x.upper(),backgroundcolor='gray')\n",
    "        \n",
    "\n",
    "        globals()[f\"ax_count_plots_{index}\"].bar(null_columns,null_column_values)\n",
    "        \n",
    "        globals()[f\"ax_count_plots_{index}\"].set(xlabel=None)\n",
    "        globals()[f\"ax_count_plots_{index}\"].tick_params(axis='x', labelrotation = 90)\n",
    "        \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_null_values(recreational_beach_monitoring,'STATION_NAME',False,2010) #false if dont want to use year filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null values\n",
    "pd.set_option('display.max_rows',None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "recreational_beach_monitoring.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This is just an example of a line graph, visualization can be better\n",
    "def linechart_of_categories(dataset,group_by,time_column,value_column,year_filter_switch,year_filter):\n",
    "    if year_filter_switch:\n",
    "        dataset = dataset[(dataset['YEAR'] == year_filter)]\n",
    "\n",
    "    dataset = dataset.set_index(time_column)\n",
    "    dataset = dataset.groupby([group_by])\n",
    "    # extract keys from groups\n",
    "    keys = dataset.groups.keys()\n",
    "    totalRows = 0\n",
    "    for index, x in enumerate(keys):\n",
    "        if(len(dataset[value_column].get_group(x))!=dataset[value_column].get_group(x).isna().sum()):\n",
    "            totalRows+=1\n",
    "    \n",
    "    totalCols=3\n",
    "    totalRows=math.ceil(totalRows/totalCols)\n",
    "    \n",
    "    fig = plt.figure(figsize=((totalCols+3)*3,(totalRows+1)*5))\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.6)\n",
    "    newInx = 1\n",
    "    for index, x in enumerate(keys):\n",
    "        if(len(dataset[value_column].get_group(x))!=dataset[value_column].get_group(x).isna().sum()):\n",
    "            globals()[f\"ax_count_plots_{index}\"] = fig.add_subplot(totalRows,totalCols,newInx)\n",
    "            globals()[f\"ax_count_plots_{index}\"].set_title(x.upper())\n",
    "            #if(len(dataset[value_column].get_group(x))!=dataset[value_column].get_group(x).isna().sum()):\n",
    "            dataset[value_column].get_group(x).plot()\n",
    "            \n",
    "            globals()[f\"ax_count_plots_{index}\"].set(xlabel=None)\n",
    "            globals()[f\"ax_count_plots_{index}\"].tick_params(axis='x', labelrotation = 90)\n",
    "            newInx+=1\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linechart_of_categories(recreational_beach_monitoring,'STATION_NAME','DATE','E_COLI_MPN',False,2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display unique values\n",
    "\n",
    "def unique_values__or_count(listOfColumns,options,dataset):\n",
    "    for x in range(0, len(listOfColumns), 1):\n",
    "        if(options==\"unique\"):\n",
    "            unique_values_str = dataset[listOfColumns[x]].unique()\n",
    "            print(\"unique_values \" + listOfColumns[x])\n",
    "            print(unique_values_str)\n",
    "            print(\"------------------------\")\n",
    "        if(options==\"count\"):\n",
    "            values_distribution = dataset[listOfColumns[x]].value_counts()\n",
    "            print(\"-----------\"+listOfColumns[x] +\"------------\")\n",
    "            print(values_distribution)\n",
    "            print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check station values\n",
    "\n",
    "unique_values__or_count(['ENT_MPN_FLAG'],\"unique\",recreational_beach_monitoring)\n",
    "\n",
    "#\"AIR_TEMP_SOURCE\", \"E_COLI_MPN_SOURCE\", \"EC_MF_SOURCE\", \"ENT_MPN_SOURCE\", \"PH_FIELD_SOURCE\", \"TEMP_FIELD_SOURCE\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import cleaned data \n",
    "\n",
    "recreational_beach_monitoring_validate = pd.read_csv(\"data/recreational_beach_monitoring.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_validate.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Col_name_to_validate = \"E_COLI_MPN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_validate[\"DATE\"] = pd.to_datetime(recreational_beach_monitoring_validate[\"DATE\"],format='%Y/%m/%d')\n",
    "recreational_beach_monitoring_validate = recreational_beach_monitoring_validate[[\"STATION_NAME\", \"DATE\", Col_name_to_validate]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import original data \n",
    "\n",
    "recreational_beach_monitoring_original = pd.read_csv(\"raw_data/2000-2022.csv\", low_memory=False, sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"List of Columns\")\n",
    "print(recreational_beach_monitoring_original.columns.to_list())\n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_validate_with = \"E_coli-MPN (MPN/100ml) RPC-Lab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns \n",
    "recreational_beach_monitoring_original.rename(columns={'Station': 'STATION_NAME', 'FromDate': 'DATE',col_to_validate_with:Col_name_to_validate}, inplace=True)\n",
    "\n",
    "#recreational_beach_monitoring_original = recreational_beach_monitoring_original.rename(columns=lambda x: clean_column_names(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change date format\n",
    "recreational_beach_monitoring_original[\"DATE\"] = pd.to_datetime(recreational_beach_monitoring_original[\"DATE\"],format='%Y/%m/%d')\n",
    "\n",
    "#Trim data to validate an analyte\n",
    "recreational_beach_monitoring_original = recreational_beach_monitoring_original[[\"STATION_NAME\", \"DATE\", Col_name_to_validate]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreational_beach_monitoring_validate_results = pd.merge(recreational_beach_monitoring_validate, recreational_beach_monitoring_original, on=[\"STATION_NAME\", \"DATE\",Col_name_to_validate], how='right', indicator='Exist')\n",
    "recreational_beach_monitoring_validate_results['Exist'] = np.where(recreational_beach_monitoring_validate_results.Exist == 'both', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values__or_count(['Exist'],\"count\",recreational_beach_monitoring_validate_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_missing_rows = recreational_beach_monitoring_validate_results[(recreational_beach_monitoring_validate_results['Exist'] == False)].copy()\n",
    "\n",
    "list_of_missing_rows.head(5)\n",
    "\n",
    "#ist_of_missing_rows.to_csv(\"data/temp.csv\", sep=',',index=False,encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c481cd3fc83eb5588546703e9d94f1058347710cd104ca041365c752440aa931"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
